{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b696852-0b5b-42ba-9ce6-bd81aff52c82",
   "metadata": {},
   "source": [
    "# üìö Book Recommender System (BPR Model)\n",
    "\n",
    "This project implements a **Bayesian Personalized Ranking (BPR)** based\n",
    "neural collaborative filtering model for book recommendation.\n",
    "\n",
    "The system:\n",
    "- Trains on implicit feedback (user-book interactions)\n",
    "- Learns user and book embeddings\n",
    "- Evaluates ranking quality using HitRate and NDCG\n",
    "- Provides interactive recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b7b35b-07c5-4975-94b9-caeaa834e3af",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ac267da-2e69-4ae1-89d0-b427a85713e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc83479-adb9-44cc-b7ce-fd273928c5d9",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "677f6ff5-42ed-4c19-b5d9-9d14fbedb509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:\n",
      "Total ratings: 981756\n",
      "Users: 53424\n",
      "Books: 10000\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"data/ratings.csv\")\n",
    "\n",
    "print(\"Before filtering:\")\n",
    "print(\"Total ratings:\", len(ratings))\n",
    "print(\"Users:\", ratings.user_id.nunique())\n",
    "print(\"Books:\", ratings.book_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996b0f3-5c19-48a2-ad43-e9edb130130a",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Filter Sparse Users & Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f3d39c4-a35f-4020-b9ca-edecc00838cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering:\n",
      "Total ratings: 932940\n",
      "Users: 35710\n",
      "Books: 10000\n"
     ]
    }
   ],
   "source": [
    "min_user_ratings = 5\n",
    "min_book_ratings = 5\n",
    "\n",
    "user_counts = ratings.user_id.value_counts()\n",
    "ratings = ratings[ratings.user_id.isin(user_counts[user_counts >= min_user_ratings].index)]\n",
    "\n",
    "book_counts = ratings.book_id.value_counts()\n",
    "ratings = ratings[ratings.book_id.isin(book_counts[book_counts >= min_book_ratings].index)]\n",
    "\n",
    "print(\"\\nAfter filtering:\")\n",
    "print(\"Total ratings:\", len(ratings))\n",
    "print(\"Users:\", ratings.user_id.nunique())\n",
    "print(\"Books:\", ratings.book_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd13da-d4e3-4bc4-9d47-1b38ce05784d",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e069bb9-6397-41dc-ae57-71a35709f926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 897230\n",
      "Test size: 35710\n"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for user_id, user_data in ratings.groupby(\"user_id\"):\n",
    "    user_data = user_data.sample(frac=1, random_state=42)\n",
    "    test_list.append(user_data.iloc[0])\n",
    "    train_list.append(user_data.iloc[1:])\n",
    "\n",
    "train_df = pd.concat(train_list)\n",
    "test_df = pd.DataFrame(test_list)\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Test size:\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad77addd-4015-4652-8718-3f5ff183af17",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Encode Users & Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eecb1a86-bc28-4ccd-8aca-113bef856ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded users: 35710\n",
      "Encoded books: 10000\n"
     ]
    }
   ],
   "source": [
    "user2idx = {u: i for i, u in enumerate(train_df.user_id.unique())}\n",
    "book2idx = {b: i for i, b in enumerate(train_df.book_id.unique())}\n",
    "\n",
    "train_df[\"user_idx\"] = train_df.user_id.map(user2idx)\n",
    "train_df[\"book_idx\"] = train_df.book_id.map(book2idx)\n",
    "\n",
    "test_df[\"user_idx\"] = test_df.user_id.map(user2idx)\n",
    "test_df[\"book_idx\"] = test_df.book_id.map(book2idx)\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "num_users = len(user2idx)\n",
    "num_books = len(book2idx)\n",
    "\n",
    "print(\"Encoded users:\", num_users)\n",
    "print(\"Encoded books:\", num_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d332c367-8e35-4e7a-aeaa-010fa3f5232f",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ BPR Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c14aafa6-686a-424d-ac3a-d788e9c4cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRModel(nn.Module):\n",
    "    def __init__(self, num_users, num_books, emb_dim=256):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.book_emb = nn.Embedding(num_books, emb_dim)\n",
    "\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.book_emb.weight, std=0.01)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_vec = self.user_emb(user)\n",
    "        item_vec = self.book_emb(item)\n",
    "        return (user_vec * item_vec).sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b2d5d-fb93-4e29-b31c-da045f6834bc",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Training Setup\n",
    "\n",
    "This section prepares everything required for model training:\n",
    "\n",
    "‚Ä¢ Build user interaction history  \n",
    "‚Ä¢ Define BPR training dataset  \n",
    "‚Ä¢ Initialize DataLoader  \n",
    "‚Ä¢ Initialize model and optimizer  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "104fcb86-721a-4a85-a296-5dd2f6ac04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_seen = train_df.groupby(\"user_idx\")[\"book_idx\"].apply(set).to_dict()\n",
    "\n",
    "class BPRDataset(Dataset):\n",
    "    def __init__(self, train_df, num_books, user_seen, num_negatives=10):\n",
    "        self.users = train_df.user_idx.values\n",
    "        self.pos_items = train_df.book_idx.values\n",
    "        self.num_books = num_books\n",
    "        self.user_seen = user_seen\n",
    "        self.num_negatives = num_negatives\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.users[idx]\n",
    "        pos_item = self.pos_items[idx]\n",
    "\n",
    "        negatives = []\n",
    "        while len(negatives) < self.num_negatives:\n",
    "            neg_item = random.randint(0, self.num_books - 1)\n",
    "            if neg_item not in self.user_seen[user]:\n",
    "                negatives.append(neg_item)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(user, dtype=torch.long),\n",
    "            torch.tensor(pos_item, dtype=torch.long),\n",
    "            torch.tensor(negatives, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    BPRDataset(train_df, num_books, user_seen),\n",
    "    batch_size=2048,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BPRModel(num_users, num_books, emb_dim=256).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a3b40-3175-4e52-bf51-0603c2179d2b",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1a9f4266-42e3-4e42-82ae-df36e524889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6310\n",
      "Epoch 2, Loss: 0.4497\n",
      "Epoch 3, Loss: 0.4044\n",
      "Epoch 4, Loss: 0.3922\n",
      "Epoch 5, Loss: 0.3874\n",
      "Epoch 6, Loss: 0.3847\n",
      "Epoch 7, Loss: 0.3831\n",
      "Epoch 8, Loss: 0.3821\n",
      "Epoch 9, Loss: 0.3814\n",
      "Epoch 10, Loss: 0.3806\n",
      "Epoch 11, Loss: 0.3801\n",
      "Epoch 12, Loss: 0.3797\n",
      "Epoch 13, Loss: 0.3794\n",
      "Epoch 14, Loss: 0.3790\n",
      "Epoch 15, Loss: 0.3786\n",
      "Epoch 16, Loss: 0.3784\n",
      "Epoch 17, Loss: 0.3781\n",
      "Epoch 18, Loss: 0.3780\n",
      "Epoch 19, Loss: 0.3780\n",
      "Epoch 20, Loss: 0.3779\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for user, pos_item, neg_items in train_loader:\n",
    "        user = user.to(device)\n",
    "        pos_item = pos_item.to(device)\n",
    "        neg_items = neg_items.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pos_score = model(user, pos_item)\n",
    "\n",
    "        expanded_users = user.unsqueeze(1).expand_as(neg_items).reshape(-1)\n",
    "        flat_neg_items = neg_items.reshape(-1)\n",
    "\n",
    "        neg_score = model(expanded_users, flat_neg_items)\n",
    "        neg_score = neg_score.reshape(user.size(0), -1)\n",
    "\n",
    "        diff = pos_score.unsqueeze(1) - neg_score\n",
    "        loss = -F.logsigmoid(diff).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3156a-2533-4069-9e47-1e6879c17941",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Evaluation Metrics\n",
    "\n",
    "Evaluate ranking quality using:\n",
    "\n",
    "- HitRate@5\n",
    "- HitRate@10\n",
    "- NDCG@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fea7f2b0-a82f-411c-8b35-970e168ff0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ EVALUATION METRICS ================\n",
      "HitRate@5  : 0.4924\n",
      "HitRate@10 : 0.6698\n",
      "NDCG@10    : 0.3964\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "K_values = [5, 10]\n",
    "num_negatives = 100\n",
    "\n",
    "hit_rates = {k: 0 for k in K_values}\n",
    "ndcg_10 = 0\n",
    "\n",
    "all_book_indices = set(range(num_books))\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "\n",
    "    user = int(test_df.iloc[i][\"user_idx\"])\n",
    "    true_book = int(test_df.iloc[i][\"book_idx\"])\n",
    "\n",
    "    seen_books = user_seen[user]\n",
    "\n",
    "    negative_candidates = list(all_book_indices - seen_books - {true_book})\n",
    "    sampled_negatives = random.sample(negative_candidates, num_negatives)\n",
    "\n",
    "    candidate_books = sampled_negatives + [true_book]\n",
    "\n",
    "    user_tensor = torch.tensor([user] * len(candidate_books)).to(device)\n",
    "    book_tensor = torch.tensor(candidate_books).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = model(user_tensor, book_tensor)\n",
    "\n",
    "    scores = scores.cpu()\n",
    "\n",
    "    # Sort descending\n",
    "    ranked_indices = torch.argsort(scores, descending=True).numpy()\n",
    "    ranked_books = [candidate_books[idx] for idx in ranked_indices]\n",
    "\n",
    "    # Compute HitRate@K\n",
    "    for K in K_values:\n",
    "        if true_book in ranked_books[:K]:\n",
    "            hit_rates[K] += 1\n",
    "\n",
    "    # Compute NDCG@10\n",
    "    if true_book in ranked_books[:10]:\n",
    "        rank_position = ranked_books.index(true_book) + 1\n",
    "        ndcg_10 += 1 / np.log2(rank_position + 1)\n",
    "\n",
    "# Normalize\n",
    "for K in K_values:\n",
    "    hit_rates[K] /= len(test_df)\n",
    "\n",
    "ndcg_10 /= len(test_df)\n",
    "\n",
    "print(\"\\n================ EVALUATION METRICS ================\")\n",
    "print(f\"HitRate@5  : {hit_rates[5]:.4f}\")\n",
    "print(f\"HitRate@10 : {hit_rates[10]:.4f}\")\n",
    "print(f\"NDCG@10    : {ndcg_10:.4f}\")\n",
    "print(\"====================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda123c-7aef-4154-ad41-33bd5c35abdd",
   "metadata": {},
   "source": [
    "## üîü Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "518f11eb-7f52-41eb-badc-0e21211f2e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"bpr_model.pth\")\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeae697-3c5c-4429-ba61-6aa07417955d",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Reload Model for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d802005-651a-42a5-8c3a-166f345ab5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BPRModel(num_users, num_books, emb_dim=256).to(device)\n",
    "model.load_state_dict(torch.load(\"bpr_model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"\\nModel loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb7aea2-a566-413e-bdd9-ddfb7ade418d",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Interactive Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c7d82b9-3f36-4fc0-a14f-d9b3d14fbcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== BOOK RECOMMENDER SYSTEM =====\n",
      "1 - Recommend for Random User\n",
      "2 - Recommend Similar Books\n",
      "3 - Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select option (1, 2, or 3):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting recommender system. Goodbye üëã\n"
     ]
    }
   ],
   "source": [
    "book_data = pd.read_csv(\"data/books.csv\")\n",
    "\n",
    "idx2book = {v: k for k, v in book2idx.items()}\n",
    "\n",
    "def recommend_books(user_id, top_k=10):\n",
    "\n",
    "    if user_id not in user2idx:\n",
    "        print(\"User not found.\")\n",
    "        return\n",
    "\n",
    "    user_idx = user2idx[user_id]\n",
    "    seen_books = user_seen.get(user_idx, set())\n",
    "\n",
    "    user_tensor = torch.tensor([user_idx] * num_books).to(device)\n",
    "    book_tensor = torch.tensor(range(num_books)).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = model(user_tensor, book_tensor)\n",
    "\n",
    "    scores = scores.cpu()\n",
    "\n",
    "    for seen in seen_books:\n",
    "        scores[seen] = -1e9\n",
    "\n",
    "    top_indices = torch.topk(scores, top_k).indices.tolist()\n",
    "    recommended_ids = [idx2book[idx] for idx in top_indices]\n",
    "\n",
    "    recommendations = book_data.set_index(\"book_id\").loc[\n",
    "        [bid for bid in recommended_ids if bid in book_data.book_id.values]\n",
    "    ][[\"title\", \"authors\"]].reset_index()\n",
    "\n",
    "    if recommendations.empty:\n",
    "        print(\"No new books available to recommend for this user.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n===================================\")\n",
    "    print(f\"Recommendations For User: {user_id}\")\n",
    "    print(\"===================================\\n\")\n",
    "\n",
    "    for i, row in recommendations.iterrows():\n",
    "        print(f\"{i+1}. {row['title']}\")\n",
    "        print(f\"   Author: {row['authors']}\")\n",
    "        print(f\"   Book ID: {row['book_id']}\\n\")\n",
    "\n",
    "\n",
    "def recommend_similar_books(book_title, top_k=10):\n",
    "\n",
    "    book_data[\"clean_title\"] = book_data[\"title\"].str.lower().str.strip()\n",
    "\n",
    "    matched = book_data[\n",
    "        book_data[\"clean_title\"].str.contains(book_title.lower(), na=False)\n",
    "    ]\n",
    "\n",
    "    if matched.empty:\n",
    "        print(\"No matching books found.\")\n",
    "        return\n",
    "\n",
    "    matched = matched.head(10)\n",
    "\n",
    "    print(\"\\nMatched Books:\")\n",
    "    print(\"===================================\")\n",
    "\n",
    "    for i, row in enumerate(matched.itertuples()):\n",
    "        print(f\"{i} - {row.title}\")\n",
    "        print(f\"    Author: {row.authors}\")\n",
    "        print(f\"    Book ID: {row.book_id}\\n\")\n",
    "\n",
    "    selected_idx = int(input(\"Enter the number of the book you want: \"))\n",
    "\n",
    "    selected_book = matched.iloc[selected_idx]\n",
    "    book_id = selected_book[\"book_id\"]\n",
    "\n",
    "    print(\"\\nYou selected:\")\n",
    "    print(\"-----------------------------------\")\n",
    "    print(f\"Title : {selected_book['title']}\")\n",
    "    print(f\"Author: {selected_book['authors']}\")\n",
    "    print(f\"Book ID: {book_id}\")\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"1 - Finalize this book\")\n",
    "    print(\"2 - Show similar books\")\n",
    "\n",
    "    choice = input(\"Select option (1 or 2): \")\n",
    "\n",
    "    if choice == \"1\":\n",
    "        print(\"\\nBook finalized. Returning to main menu.\")\n",
    "        return\n",
    "\n",
    "    if book_id not in book2idx:\n",
    "        print(\"\\nThis book was filtered out during training.\")\n",
    "        return\n",
    "\n",
    "    book_idx = book2idx[book_id]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        book_embedding = model.book_emb.weight[book_idx]\n",
    "        scores = torch.matmul(model.book_emb.weight, book_embedding).cpu()\n",
    "\n",
    "    scores[book_idx] = -1e9\n",
    "\n",
    "    top_indices = torch.topk(scores, top_k).indices.tolist()\n",
    "    recommended_ids = [idx2book[idx] for idx in top_indices]\n",
    "\n",
    "    recommendations = book_data.set_index(\"book_id\").loc[\n",
    "        [bid for bid in recommended_ids if bid in book_data.book_id.values]\n",
    "    ][[\"title\", \"authors\"]].reset_index()\n",
    "\n",
    "    print(\"\\n===================================\")\n",
    "    print(f\"Books Similar To: {selected_book['title']}\")\n",
    "    print(\"===================================\\n\")\n",
    "\n",
    "    if recommendations.empty:\n",
    "        print(\"No similar books found in training set.\\n\")\n",
    "    else:\n",
    "        for i, row in recommendations.iterrows():\n",
    "            print(f\"{i+1}. {row['title']}\")\n",
    "            print(f\"   Author: {row['authors']}\")\n",
    "            print(f\"   Book ID: {row['book_id']}\\n\")\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(\"\\n===== BOOK RECOMMENDER SYSTEM =====\")\n",
    "    print(\"1 - Recommend for Random User\")\n",
    "    print(\"2 - Recommend Similar Books\")\n",
    "    print(\"3 - Exit\")\n",
    "\n",
    "    choice = input(\"\\nSelect option (1, 2, or 3): \").strip()\n",
    "\n",
    "    if choice == \"1\":\n",
    "        random_user = random.choice(list(user2idx.keys()))\n",
    "        print(\"\\nRandom demo user selected:\", random_user)\n",
    "        recommend_books(random_user)\n",
    "\n",
    "    elif choice == \"2\":\n",
    "        book_input = input(\"\\nEnter part of a book title: \").strip()\n",
    "        recommend_similar_books(book_input)\n",
    "\n",
    "    elif choice == \"3\":\n",
    "        print(\"\\nExiting recommender system. Goodbye üëã\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12794418-0b42-45ab-8f5c-4b9f667ede52",
   "metadata": {},
   "source": [
    "## üìä Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab9968ff-0097-4651-aa21-453aa97fafd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ DATASET ANALYSIS ================\n",
      "\n",
      "Dataset Statistics:\n",
      "Total Users        : 35710\n",
      "Total Books        : 10000\n",
      "Total Ratings      : 932940\n",
      "Sparsity           : 0.9974\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "TOP 10 MOST POPULAR BOOKS\n",
      "============================================================\n",
      "1. Harry Potter and the Half-Blood Prince (Harry Potter, #6)  | Ratings: 100\n",
      "2. Dreamland  | Ratings: 100\n",
      "3. In Our Time  | Ratings: 100\n",
      "4. The Snows of Kilimanjaro and Other Stories  | Ratings: 100\n",
      "5. A Moveable Feast  | Ratings: 100\n",
      "6. To Have and Have Not  | Ratings: 100\n",
      "7. Carter Beats the Devil  | Ratings: 100\n",
      "8. Extremely Loud and Incredibly Close  | Ratings: 100\n",
      "9. The View from Saturday  | Ratings: 100\n",
      "10. Olivia Joules and the Overactive Imagination  | Ratings: 100\n",
      "------------------------------------------------------------\n",
      "\n",
      "TOP 10 LEAST POPULAR BOOKS\n",
      "============================================================\n",
      "1. Ghostwritten  | Ratings: 21\n",
      "2. Jesus Freaks: Stories of Those Who Stood for Jesus, the Ultimate Jesus Freaks (Jesus Freaks, #1)  | Ratings: 31\n",
      "3. The Man From St. Petersburg  | Ratings: 33\n",
      "4. Next  | Ratings: 36\n",
      "5. Sons of Destiny (Cirque Du Freak, #12)  | Ratings: 36\n",
      "6. Shopaholic Takes Manhattan (Shopaholic, #2)  | Ratings: 36\n",
      "7. Loving What Is: Four Questions That Can Change Your Life  | Ratings: 37\n",
      "8. Jurassic Park (Jurassic Park, #1)  | Ratings: 40\n",
      "9. The Bookseller of Kabul  | Ratings: 40\n",
      "10. Peter and the Shadow Thieves (Peter and the Starcatchers, #2)  | Ratings: 42\n",
      "------------------------------------------------------------\n",
      "\n",
      "Distribution Statistics:\n",
      "Average ratings per book: 93.37\n",
      "Median ratings per book : 100.00\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n================ DATASET ANALYSIS ================\\n\")\n",
    "\n",
    "num_users = ratings.user_id.nunique()\n",
    "num_books = ratings.book_id.nunique()\n",
    "num_ratings = len(ratings)\n",
    "\n",
    "total_possible = num_users * num_books\n",
    "sparsity = 1 - (num_ratings / total_possible)\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Total Users        : {num_users}\")\n",
    "print(f\"Total Books        : {num_books}\")\n",
    "print(f\"Total Ratings      : {num_ratings}\")\n",
    "print(f\"Sparsity           : {sparsity:.4f}\")\n",
    "\n",
    "print(\"\\n--------------------------------------------------\")\n",
    "\n",
    "books = pd.read_csv(\"data/books.csv\")[[\"book_id\", \"title\"]]\n",
    "popularity = ratings.groupby(\"book_id\").size().reset_index(name=\"rating_count\")\n",
    "popularity = popularity.merge(books, on=\"book_id\", how=\"inner\")\n",
    "\n",
    "most_popular = popularity.sort_values(\"rating_count\", ascending=False).head(10)\n",
    "least_popular = popularity.sort_values(\"rating_count\", ascending=True).head(10)\n",
    "\n",
    "def print_section(df, header):\n",
    "    print(f\"\\n{header}\")\n",
    "    print(\"=\" * 60)\n",
    "    for rank, row in enumerate(df.itertuples(), 1):\n",
    "        print(f\"{rank}. {row.title}  | Ratings: {row.rating_count}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print_section(most_popular, \"TOP 10 MOST POPULAR BOOKS\")\n",
    "print_section(least_popular, \"TOP 10 LEAST POPULAR BOOKS\")\n",
    "\n",
    "print(\"\\nDistribution Statistics:\")\n",
    "print(f\"Average ratings per book: {popularity['rating_count'].mean():.2f}\")\n",
    "print(f\"Median ratings per book : {popularity['rating_count'].median():.2f}\")\n",
    "\n",
    "print(\"\\n====================================================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bookrec)",
   "language": "python",
   "name": "bookrec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
